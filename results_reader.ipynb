{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e39f35-7a3d-43db-be15-d2b0e1e222d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93097"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.Data import CodonTable\n",
    "from Bio.SeqUtils import six_frame_translations\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import os\n",
    "\n",
    "# Define the path to the input FASTA file\n",
    "\n",
    "dir_r = \"./data/raw/\"\n",
    "dir_r_cds =\"./data/raw/CDS\"\n",
    "dir_r_aa = \"./data/raw/AA\"\n",
    "dir_p = \"./data/processed/\"\n",
    "dir_f = \"./data/final/\"\n",
    "\n",
    "# Create an empty list to hold SeqRecord objects\n",
    "combined_records = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(dir_r_cds):\n",
    "    if filename.endswith(\".fna\"):\n",
    "        filepath = os.path.join(dir_r_cds, filename)\n",
    "        # Read each file and append the sequences to the combined_records list\n",
    "        with open(filepath, \"r\") as handle:\n",
    "            records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "            combined_records.extend(records)\n",
    "\n",
    "# Create a combined fasta file with all sequences\n",
    "fasta_file = os.path.join(dir_r, \"combined_sequences_cds.fasta\")\n",
    "SeqIO.write(combined_records, fasta_file, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb886e13-4f2b-4cd9-977d-a52b4e8b1c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93085"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AA Combined Sequence list\n",
    "\n",
    "# Create an empty list to hold SeqRecord objects\n",
    "combined_records = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(dir_r_aa):\n",
    "    if filename.endswith(\".faa\"):\n",
    "        filepath = os.path.join(dir_r_aa, filename)\n",
    "        # Read each file and append the sequences to the combined_records list\n",
    "        with open(filepath, \"r\") as handle:\n",
    "            records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "            combined_records.extend(records)\n",
    "\n",
    "# Create a combined fasta file with all sequences\n",
    "fasta_file = os.path.join(dir_r, \"combined_sequences_aa.fasta\")\n",
    "SeqIO.write(combined_records, fasta_file, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda14685-cd43-454c-8149-870bc615e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Defining HMM and target to analyse\n",
    "\n",
    "HMM = os.path.join(dir_p, \"enzyme.hmm\")\n",
    "Target = os.path.join(dir_r, \"combined_sequences_aa.fasta\")\n",
    "output_hits_file = os.path.join(dir_f, \"enzymehits.csv\")\n",
    "\n",
    "command = ['hmmsearch', '-o', output_hits_file, HMM, Target]\n",
    "\n",
    "\n",
    "# run the command and capture the output\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "094afbf7-2940-45ed-aa03-56ed4ac1d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format data as slightly more readable csv file\n",
    "\n",
    "import csv\n",
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "output_hits_file = os.path.join(dir_f, \"enzymehits.csv\")\n",
    "output_extr_file = os.path.join(dir_p, \"extracted_data.csv\")\n",
    "\n",
    "# Open the output file and read its contents\n",
    "with open(output_hits_file, \"r\") as file:\n",
    "    csv_reader = csv.reader(file, delimiter=\"\\t\")\n",
    "    rows = list(csv_reader)\n",
    "\n",
    "# Extract headers from row 13\n",
    "headers = ''.join(rows[13]).split()\n",
    "\n",
    "# Extract data from rows 15 onwards until an empty row is encountered\n",
    "data = []\n",
    "row_index = 15\n",
    "while row_index < len(rows) and rows[row_index]:\n",
    "    data.append(''.join(rows[row_index]).split())\n",
    "    row_index += 1\n",
    "\n",
    "# Write the extracted data to a new CSV file\n",
    "with open(output_extr_file, \"w\", newline=\"\") as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow(headers)  # Write headers\n",
    "    csv_writer.writerows(data)  # Write data rows\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d3d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue with row: ['------', 'inclusion', 'threshold', '------']\n"
     ]
    }
   ],
   "source": [
    "#Extraction of hits from CDS data based on names of top rankers in HMM search\n",
    "\n",
    "def extract_protein_id_from_header(header):\n",
    "    match = re.search(r'\\[protein_id=([^\\]]+)]', header)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "cds_hits_aa = os.path.join(dir_p, \"CDS_hits_aa.fasta\")\n",
    "\n",
    "# Read the sequence names from the CSV file with ranking\n",
    "sequence_names = []\n",
    "with open(output_extr_file, \"r\") as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        if len(row) > 8:  # Ensure that the row has at least 9 elements\n",
    "            sequence_names.append(row[8])\n",
    "        else:\n",
    "            print(f\"Issue with row: {row}\")\n",
    "\n",
    "# Extract sequences from the FASTA file for Translated Proteins\n",
    "output_fa_file = os.path.join(dir_r, \"combined_sequences_aa.fasta\")\n",
    "sequences_AA = []\n",
    "\n",
    "# Iterate over the sequence names in the order of ranking\n",
    "for sequence_name in sequence_names:\n",
    "    with open(output_fa_file, \"r\") as file:\n",
    "        fasta_data = file.read().split(\">\")[1:]\n",
    "        for entry in fasta_data:\n",
    "            entry_lines = entry.strip().split(\"\\n\")\n",
    "            header = entry_lines[0]\n",
    "            sequence = \"\".join(entry_lines[1:])\n",
    "            current_sequence_name = header.split()[0]\n",
    "            if current_sequence_name == sequence_name:\n",
    "                sequences_AA.append(f\">{header}\\n{sequence}\")\n",
    "                break  # Break once the sequence is found\n",
    "\n",
    "# Save the extracted AA sequences to a new FASTA file\n",
    "with open(cds_hits_aa, \"w\") as file:\n",
    "    file.write(\"\\n\".join(sequences_AA))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b38d2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m output_fasta_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_f,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiltered_hits_aa.fasta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m identity_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m80\u001b[39m\n\u001b[0;32m---> 38\u001b[0m filtered_sequences \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fasta_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midentity_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m SeqIO\u001b[38;5;241m.\u001b[39mwrite(filtered_sequences, output_fasta_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfasta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m num_input_sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(SeqIO\u001b[38;5;241m.\u001b[39mparse(input_fasta_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfasta\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36mfilter_sequences\u001b[0;34m(fasta_file, identity_threshold)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, seq2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sequences):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m---> 21\u001b[0m         identity \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_identity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m identity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m identity_threshold:\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;66;03m# Compare sequence identifiers\u001b[39;00m\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m seq1\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m>\u001b[39m seq2\u001b[38;5;241m.\u001b[39mid: \u001b[38;5;66;03m#If Seq1 is a worse hit than Seq2, e.g. rather take Seq2 to filtered_sequences in later iteration\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mcalculate_identity\u001b[0;34m(seq1, seq2)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_identity\u001b[39m(seq1, seq2):\n\u001b[0;32m----> 6\u001b[0m     alignments \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocalxx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_alignment_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m alignments:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# No alignment found, consider them different\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/Bio/pairwise2.py:502\u001b[0m, in \u001b[0;36malign.alignment_function.__call__\u001b[0;34m(self, *args, **keywds)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the alignment instance already created.\"\"\"\u001b[39;00m\n\u001b[1;32m    501\u001b[0m keywds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkeywds)\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_align\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeywds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/Bio/pairwise2.py:603\u001b[0m, in \u001b[0;36m_align\u001b[0;34m(sequenceA, sequenceB, match_fn, gap_A_fn, gap_B_fn, penalize_extend_when_opening, penalize_end_gaps, align_globally, gap_char, force_generic, score_only, one_alignment_only)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score_only:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_score\n\u001b[0;32m--> 603\u001b[0m starts \u001b[38;5;241m=\u001b[39m \u001b[43m_find_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_globally\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# Recover the alignments and return them.\u001b[39;00m\n\u001b[1;32m    606\u001b[0m alignments \u001b[38;5;241m=\u001b[39m _recover_alignments(\n\u001b[1;32m    607\u001b[0m     sequenceA,\n\u001b[1;32m    608\u001b[0m     sequenceB,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    617\u001b[0m     gap_B_fn,\n\u001b[1;32m    618\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/Bio/pairwise2.py:1123\u001b[0m, in \u001b[0;36m_find_start\u001b[0;34m(score_matrix, best_score, align_globally)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ncols):\n\u001b[1;32m   1122\u001b[0m             score \u001b[38;5;241m=\u001b[39m score_matrix[row][col]\n\u001b[0;32m-> 1123\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m rint(\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbest_score\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rint(tolerance):\n\u001b[1;32m   1124\u001b[0m                 starts\u001b[38;5;241m.\u001b[39mappend((score, (row, col)))\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m starts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import pairwise2\n",
    "import os\n",
    "\n",
    "def calculate_identity(seq1, seq2):\n",
    "    alignments = pairwise2.align.localxx(seq1, seq2, one_alignment_only=True)\n",
    "    if not alignments:\n",
    "        return 0.0  # No alignment found, consider them different\n",
    "    best_alignment = alignments[0]\n",
    "    identity = (best_alignment[2] / max(len(seq1), len(seq2))) * 100\n",
    "    return identity\n",
    "\n",
    "def filter_sequences(fasta_file, identity_threshold):\n",
    "    sequences = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "    filtered_sequences = []\n",
    "\n",
    "    for i, seq1 in enumerate(sequences):\n",
    "        is_unique = True\n",
    "        for j, seq2 in enumerate(sequences):\n",
    "            if i != j:\n",
    "                identity = calculate_identity(seq1.seq, seq2.seq)\n",
    "                if identity >= identity_threshold:\n",
    "                    # Compare sequence identifiers\n",
    "                    if seq1.id > seq2.id: #If Seq1 is a worse hit than Seq2, e.g. rather take Seq2 to filtered_sequences in later iteration\n",
    "                        is_unique = False\n",
    "                        break\n",
    "\n",
    "        if is_unique:\n",
    "            filtered_sequences.append(seq1)\n",
    "\n",
    "    return filtered_sequences\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_fasta_file = os.path.join(dir_p,\"CDS_hits_aa.fasta\")\n",
    "    output_fasta_file = os.path.join(dir_f,\"filtered_hits_aa.fasta\")\n",
    "    identity_threshold = 80\n",
    "\n",
    "    filtered_sequences = filter_sequences(input_fasta_file, identity_threshold)\n",
    "\n",
    "    SeqIO.write(filtered_sequences, output_fasta_file, \"fasta\")\n",
    "\n",
    "    num_input_sequences = len(list(SeqIO.parse(input_fasta_file, \"fasta\")))\n",
    "    num_removed_sequences = num_input_sequences - len(filtered_sequences)\n",
    "    print(f\"{num_removed_sequences} protein sequences were removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786a6bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 protein sequences were removed.\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import pairwise2\n",
    "import os\n",
    "\n",
    "def calculate_identity(seq1, seq2):\n",
    "    alignments = pairwise2.align.localxx(seq1, seq2, one_alignment_only=True)\n",
    "    if not alignments:\n",
    "        return 0.0  # No alignment found, consider them different\n",
    "    best_alignment = alignments[0]\n",
    "    identity = (best_alignment[2] / max(len(seq1), len(seq2))) * 100\n",
    "    return identity\n",
    "\n",
    "def filter_sequences(fasta_file, identity_threshold):\n",
    "    sequences = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "    filtered_sequences = []\n",
    "\n",
    "    fnon_unique_indices = set()\n",
    "\n",
    "    for i, seq1 in enumerate(sequences):\n",
    "    # Skip sequences already deemed non-unique\n",
    "        if i in non_unique_indices:\n",
    "            continue\n",
    "\n",
    "        is_unique = True\n",
    "\n",
    "        for j, seq2 in enumerate(sequences):\n",
    "            if i != j and j not in non_unique_indices:  # Skip comparisons with self and already non-unique sequences\n",
    "                identity = calculate_identity(seq1.seq, seq2.seq)\n",
    "\n",
    "                if identity >= identity_threshold:\n",
    "                    # Compare sequence identifiers\n",
    "                    if seq1.id > seq2.id: #If Seq1 is a worse hit than Seq2\n",
    "                        is_unique = False\n",
    "                        non_unique_indices.add(i)  # Mark seq2 as non-unique\n",
    "                    else: #If Seq2 is a worse hit than Seq1\n",
    "                        non_unique_indices.add(j)  # Mark seq1 as non-unique\n",
    "                        break  # No need to continue comparing seq1 with other sequences\n",
    "\n",
    "        if is_unique:\n",
    "            filtered_sequences.append(seq1)\n",
    "\n",
    "\n",
    "    return filtered_sequences\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_fasta_file = os.path.join(dir_p,\"CDS_hits_aa.fasta\")\n",
    "    output_fasta_file = os.path.join(dir_f,\"filtered_hits_aa.fasta\")\n",
    "    identity_threshold = 80\n",
    "    non_unique_indices = set()\n",
    "\n",
    "    filtered_sequences = filter_sequences(input_fasta_file, identity_threshold)\n",
    "\n",
    "    SeqIO.write(filtered_sequences, output_fasta_file, \"fasta\")\n",
    "\n",
    "    num_input_sequences = len(list(SeqIO.parse(input_fasta_file, \"fasta\")))\n",
    "    num_removed_sequences = num_input_sequences - len(filtered_sequences)\n",
    "    print(f\"{num_removed_sequences} protein sequences were removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d9e6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 4 nucleotide sequences to ./data/final/240221_4amidases_cds.fasta.\n"
     ]
    }
   ],
   "source": [
    "# Extract sequences from the filtered FASTA file, but get the DNA sequences\n",
    "\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Function to extract protein ID from header with variable structure\n",
    "def extract_protein_id_from_aa_header(header):\n",
    "    match = re.search(r'(\\S+)', header.split()[0])\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def extract_protein_id_from_cds_header(header):\n",
    "    match = re.search(r'\\[protein_id=([^\\]]+)]', header)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Define file paths\n",
    "\n",
    "#input_fasta_file = os.path.join(dir_f,\"filtered_hits_aa.fasta\")#test\n",
    "input_fasta_file = os.path.join(dir_f,\"240221_4amidases.fasta\") #real file\n",
    "\n",
    "fasta_file = os.path.join(dir_r, \"combined_sequences_cds.fasta\") \n",
    "\n",
    "#output_fasta_file = os.path.join(dir_f,\"filtered_hits_dna.fasta\") #real file\n",
    "output_fasta_file = os.path.join(dir_f,\"240221_4amidases_cds.fasta\") # test\n",
    "\n",
    "# Create a set of protein IDs from the AA filtered hits fasta file\n",
    "protein_ids_to_extract = set()\n",
    "for record in SeqIO.parse(input_fasta_file, \"fasta\"):\n",
    "    protein_id = extract_protein_id_from_aa_header(record.description)\n",
    "    if protein_id:\n",
    "        protein_ids_to_extract.add(protein_id)\n",
    "\n",
    "# Extract nucleotide sequences from the giant CDS.fasta file\n",
    "with open(output_fasta_file, \"w\") as output_fasta:\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        protein_id = extract_protein_id_from_cds_header(record.description)\n",
    "        if protein_id and protein_id in protein_ids_to_extract:\n",
    "            SeqIO.write(record, output_fasta, \"fasta\")\n",
    "\n",
    "print(f\"Extracted {len(protein_ids_to_extract)} nucleotide sequences to {output_fasta_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5e5afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in ./data/final/filtered_hits_dna.fasta: 106\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "def count_entries(fasta_file):\n",
    "    return sum(1 for _ in SeqIO.parse(fasta_file, \"fasta\"))\n",
    "\n",
    "# Example usage\n",
    "fasta_file_path = os.path.join(dir_f, \"filtered_hits_dna.fasta\")\n",
    "num_entries = count_entries(fasta_file_path)\n",
    "print(f\"Number of entries in {fasta_file_path}: {num_entries}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4628e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following code is to help evaluate the GFF3 results from SP06\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "from typing import List, Dict, Union\n",
    "from teemi.design.combinatorial_design import simple_amplicon_maker\n",
    "from pydna.design import primer_design\n",
    "from pydna.dseqrecord import Dseqrecord\n",
    "\n",
    "\n",
    "def open_gff3_files(path: str = \"\") -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Opens and reads a GFF3 file and returns its contents as a list of lists.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path: str\n",
    "        The path to the GFF3 file.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    List[List[str]]\n",
    "        A list of lists containing the contents of the GFF3 file.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as infile:\n",
    "        LINES = []\n",
    "        for line in infile:\n",
    "            LINES.append(line[:].split(\"\\t\"))\n",
    "        LINES = LINES[1:]\n",
    "\n",
    "    return LINES\n",
    "\n",
    "import re\n",
    "\n",
    "def tidy_up_gff(lst_of_gff: list) -> list:\n",
    "    \"\"\"\n",
    "    This function takes a list of GFF lines and returns a list of dictionaries,\n",
    "    with each dictionary containing information on the signal peptides in the GFF file.\n",
    "\n",
    "    Parameters:\n",
    "    lst_of_gff (list): A list of GFF lines.\n",
    "\n",
    "    Returns:\n",
    "    list_of_peptides (list): A list of dictionaries, with each dictionary containing information on the signal peptides in the GFF file.\n",
    "    \"\"\"\n",
    "    list_of_peptides = []\n",
    "\n",
    "    for peptide in lst_of_gff:\n",
    "        # Splitting the gene attribute to extract the first protein name\n",
    "        gene_attribute_parts = peptide[0].split()\n",
    "        first_protein_name = gene_attribute_parts[0]\n",
    "\n",
    "        signal_peptides = {\n",
    "            \"gene\": first_protein_name,\n",
    "            \"start_pos\": int(peptide[3]) - 1,\n",
    "            \"end_pos\": int(peptide[4]) + 1,\n",
    "            \"signal_peptide_likelyhood\": peptide[5],\n",
    "        }\n",
    "\n",
    "        list_of_peptides.append(signal_peptides)\n",
    "\n",
    "    return list_of_peptides\n",
    "\n",
    "\n",
    "def dict_of_signal_peptides(path: str = \"\") -> List[Dict[str, Union[str, int]]]:\n",
    "    \"\"\"\n",
    "    Given a path to a GFF3 file, returns a list of dictionaries with information on signal peptides.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the GFF3 file. Default is an empty string.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries where each dictionary contains the following keys:\n",
    "            - 'gene' (str): Gene name of the signal peptide.\n",
    "            - 'start_pos' (int): Start position of the signal peptide in the protein sequence.\n",
    "            - 'end_pos' (int): End position of the signal peptide in the protein sequence.\n",
    "            - 'signal_peptide_likelyhood' (str): The likelihood of the sequence being a signal peptide.\n",
    "    \"\"\"\n",
    "    gff = open_gff3_files(path)\n",
    "    dict_of_signal_peptides = tidy_up_gff(gff)\n",
    "    return dict_of_signal_peptides\n",
    "\n",
    "\n",
    "def read_gff_to_pd(path: str = \"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a GFF3 file and returns a pandas DataFrame with columns 'gene', 'start_pos', 'end_pos',\n",
    "    and 'signal_peptide_likelyhood'.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        The path to the GFF3 file.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    df : pandas.DataFrame\n",
    "        A DataFrame with columns 'gene', 'start_pos', 'end_pos', and 'signal_peptide_likelyhood'.\n",
    "    \"\"\"\n",
    "\n",
    "    gff = open_gff3_files(path)\n",
    "    dict_of_signal_peptides = tidy_up_gff(gff)\n",
    "    df = pd.DataFrame.from_records(dict_of_signal_peptides)\n",
    "\n",
    "    return df\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def primer_ta_neb(primer1, primer2, conc=0.4, prodcode=\"phusion-0\"):\n",
    "    \"\"\"Calculates primer pair melting temp TA,  from NEB.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    primer1 : str\n",
    "        first primer to be used for finding the optimal ta\n",
    "    primer2 : str\n",
    "        second primer to be used for finding the optimal ta\n",
    "    conc : float\n",
    "    prodcode : str\n",
    "        find product codes on nebswebsite: https://tmapi.neb.com/docs/productcodes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ta : int\n",
    "        primer pair annealing temp\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"https://tmapi.neb.com/tm/batch\"\n",
    "    seqpairs = [[primer1, primer2]]\n",
    "\n",
    "    input = {\"seqpairs\": seqpairs, \"conc\": conc, \"prodcode\": prodcode}\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "    res = requests.post(url, data=json.dumps(input), headers=headers)\n",
    "\n",
    "    r = json.loads(res.content)\n",
    "\n",
    "    if r[\"success\"]:\n",
    "        for row in r[\"data\"]:\n",
    "            return row[\"ta\"]\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(r[\"error\"][0])\n",
    "\n",
    "\n",
    "def primer_tm_neb1(primer, conc=0.4, prodcode=\"phusion-0\"):\n",
    "    \"\"\"Calculates a single primers melting temp from NEB.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    primer1 : str\n",
    "    conc : float\n",
    "    prodcode : str\n",
    "        find product codes on nebswebsite: https://tmapi.neb.com/docs/productcodes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tm : int\n",
    "        primer melting temperature\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"https://tmapi.neb.com/tm/batch\"\n",
    "    seqpairs = [[primer]]\n",
    "\n",
    "    input = {\"seqpairs\": seqpairs, \"conc\": conc, \"prodcode\": prodcode}\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "    res = requests.post(url, data=json.dumps(input), headers=headers)\n",
    "\n",
    "    r = json.loads(res.content)\n",
    "\n",
    "    if r[\"success\"]:\n",
    "        for row in r[\"data\"]:\n",
    "            return row[\"tm1\"]\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(r[\"error\"][0])\n",
    "        \n",
    "\n",
    "\n",
    "def make_amplicons(\n",
    "    list_of_amplicons: list, target_tm=58, limit=10, tm_function=primer_tm_neb1,\n",
    "    forward_overhang=\"TTTTTTTTTT\", reverse_overhang=\"CCCCCCCC\" ):\n",
    "    \"\"\"Generates pydna.amplicons which contains primers with a target temperature.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_amplicons : list\n",
    "        list of pydna.Dseqrecords\n",
    "    target_tm : int\n",
    "        representing the target melting temperature for the primers (default=55)\n",
    "    limit: int\n",
    "        representing the minimum primer size (default=5)\n",
    "    tm_function : function\n",
    "        for calculating primer melting temperature (default=primer_tm_neb)\n",
    "\n",
    "    forward_overhang : str\n",
    "        forward overhang sequence (default=\"TTTTTTTTTT\")\n",
    "    reverse_overhang : str\n",
    "        reverse overhang sequence (default=\"CCCCCCCC\")\n",
    "\n",
    "    Returns:\n",
    "    amplicons: list\n",
    "        list of amplicon objects with designed primer sequences\n",
    "    \"\"\"\n",
    "    amplicons = []\n",
    "    for i in range(len(list_of_amplicons)):\n",
    "        amplicon = primer_design(\n",
    "            list_of_amplicons[i],\n",
    "            target_tm=target_tm,\n",
    "            limit=limit,\n",
    "            tm_function=tm_function,\n",
    "\n",
    "            f_overhang=forward_overhang,\n",
    "            r_overhang=reverse_overhang,\n",
    "        )\n",
    "\n",
    "        amplicons.append(amplicon)\n",
    "\n",
    "    return amplicons\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce62fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: lcl|KV907505.1_cds_OOF92982.1_7994\n",
      "Name: lcl|KV907505.1_cds_OOF92982.1_7994\n",
      "Description: lcl|KV907505.1_cds_OOF92982.1_7994 [locus_tag=ASPCADRAFT_508787] [db_xref=InterPro:IPR000120,JGIDB:Aspca3_508787] [protein=hypothetical protein] [protein_id=OOF92982.1] [location=185392..187512] [gbkey=CDS]\n",
      "Number of features: 0\n",
      "Seq('ATGGCATGGCTGTTTCCTCTCGTTTTCATTATGAGCCTCGTTGGGACACCTGCT...TGA')\n",
      "ID: lcl|KV907515.1_cds_OOF90661.1_10513\n",
      "Name: lcl|KV907515.1_cds_OOF90661.1_10513\n",
      "Description: lcl|KV907515.1_cds_OOF90661.1_10513 [locus_tag=ASPCADRAFT_58797] [db_xref=InterPro:IPR000120,JGIDB:Aspca3_58797] [protein=hypothetical protein] [protein_id=OOF90661.1] [location=complement(join(119270..119769,119829..121236))] [gbkey=CDS]\n",
      "Number of features: 0\n",
      "Seq('ATGGTGCGTCTGGCCCAGCTCGCCGTGTCGGCTCTCGGGCTGGTCGGCACAGCG...TGA')\n",
      "ID: lcl|NC_036441.1_cds_XP_001826005.1_10339\n",
      "Name: lcl|NC_036441.1_cds_XP_001826005.1_10339\n",
      "Description: lcl|NC_036441.1_cds_XP_001826005.1_10339 [locus_tag=AO090011000357] [db_xref=GeneID:5998108] [protein_id=XP_001826005.1] [location=join(914179..914492,914550..916008)] [gbkey=CDS]\n",
      "Number of features: 0\n",
      "Seq('ATGGTCTCGAAAGTGTTCGGTCGACTTTTGACCACCGGCCTTGTATTGGCAAAC...TAA')\n",
      "ID: NC_036440.1:c3236563-3235134\n",
      "Name: NC_036440.1:c3236563-3235134\n",
      "Description: NC_036440.1:c3236563-3235134 Aspergillus oryzae RIB40 DNA, chromosome 6 (MODIFIED)\n",
      "Number of features: 0\n",
      "Seq('ATGCCATCTGCCAGCTGGGAAGATCTCGCTGCCGACAAGAGGGCACGTTTGGAG...TAG')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': ['OOF90661.1', 'XP_001826005.1', 'OOF92982.1'], 'n_pos': [21, 28, 23]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining the Nucleotide sequences that correspond to the .gff3 summary file\n",
    "sequences = list()\n",
    "fasta_file_path = os.path.join(dir_f, \"240221_4amidases_cds.fasta\")\n",
    "for sequence in SeqIO.parse(fasta_file_path,format='fasta'):\n",
    "    print(sequence)\n",
    "    sequences.append(sequence)\n",
    "    \n",
    "#Reads .gff3 generated by signalp06 and the corresponding amino acid sequence fasta file (Code by Lucas Levassor)\n",
    "from Bio import SeqIO\n",
    "\n",
    "signal_pep = read_gff_to_pd(os.path.join(dir_f,'240221_4amidasesgff3.gff3'))\n",
    "signal_pep\n",
    "\n",
    "N_pos = signal_pep['end_pos'].to_list()\n",
    "genes_with_signal_peptides = signal_pep['gene'].to_list()\n",
    "\n",
    "my_dict = {'name':genes_with_signal_peptides, 'n_pos':N_pos }\n",
    "my_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540feb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SeqRecord(seq=Seq('GTGTCTACGGGCATGTCCGTCACGCTGGATAACATCAACTACTTCATCTCGCCC...TTT'), id='lcl|KV907515.1_cds_OOF90661.1_10513', name='lcl|KV907515.1_cds_OOF90661.1_10513', description='lcl|KV907515.1_cds_OOF90661.1_10513 [locus_tag=ASPCADRAFT_58797] [db_xref=InterPro:IPR000120,JGIDB:Aspca3_58797] [protein=hypothetical protein] [protein_id=OOF90661.1] [location=complement(join(119270..119769,119829..121236))] [gbkey=CDS]', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('GATAGTTTAGTTGCATCTCAGGTTGTGACAAATCCCTATGAATATGATTTCCCT...ATG'), id='lcl|NC_036441.1_cds_XP_001826005.1_10339', name='lcl|NC_036441.1_cds_XP_001826005.1_10339', description='lcl|NC_036441.1_cds_XP_001826005.1_10339 [locus_tag=AO090011000357] [db_xref=GeneID:5998108] [protein_id=XP_001826005.1] [location=join(914179..914492,914550..916008)] [gbkey=CDS]', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('CTGGAGATGCAGAACATGGACGTCACCCTGGAAAGAGGCATCACATTCGACCTG...TTT'), id='lcl|KV907505.1_cds_OOF92982.1_7994', name='lcl|KV907505.1_cds_OOF92982.1_7994', description='lcl|KV907505.1_cds_OOF92982.1_7994 [locus_tag=ASPCADRAFT_508787] [db_xref=InterPro:IPR000120,JGIDB:Aspca3_508787] [protein=hypothetical protein] [protein_id=OOF92982.1] [location=185392..187512] [gbkey=CDS]', dbxrefs=[]),\n",
       " SeqRecord(seq=Seq('CCATCTGCCAGCTGGGAAGATCTCGCTGCCGACAAGAGGGCACGTTTGGAGAAG...CCG'), id='NC_036440.1:c3236563-3235134', name='NC_036440.1:c3236563-3235134', description='NC_036440.1:c3236563-3235134 Aspergillus oryzae RIB40 DNA, chromosome 6 (MODIFIED)', dbxrefs=[])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Truncation of coding sequences for correct primer generation\n",
    "\n",
    "clean_seq = list()\n",
    "\n",
    "for i in range(len(genes_with_signal_peptides)):\n",
    "    gene_id = genes_with_signal_peptides[i]\n",
    "    for seq in sequences:\n",
    "        if gene_id in seq.id:\n",
    "            clean_seq.append(seq[(N_pos[i]+1) * 3:-3]) #Removes one amino acid extra to accomodate for peptidase cleavage site leftovers\n",
    "            break  # Break the loop if a match is found\n",
    "\n",
    "# Add sequences that didn't match\n",
    "for seq in sequences:\n",
    "   if all(gene_id not in seq.description for gene_id in genes_with_signal_peptides):\n",
    "        clean_seq.append(seq[3:-3]) #still needs to remove ATG to accomodate signal peptide ATG instead. Also needs to remove stop codon.\n",
    "\n",
    "clean_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6717e13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1839, 1683, 2046, 1349]\n"
     ]
    }
   ],
   "source": [
    "# Get the sequence lengths\n",
    "seq_lengths = [len(seq) for seq in clean_seq]\n",
    "\n",
    "# Print or use seq_lengths as needed\n",
    "print(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3933937",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_seq = [Dseqrecord(seq) for seq in clean_seq]\n",
    "\n",
    "amplicons = make_amplicons(clean_seq,\n",
    "                           target_tm=62, # target temp\n",
    "                           limit=18,  # min length of primers\n",
    "                           tm_function = primer_tm_neb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83dbc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_primer = [str(f.forward_primer.seq) for f in amplicons]\n",
    "r_primer = [str(r.reverse_primer.seq) for r in amplicons]\n",
    "name = [str(r.name) for r in amplicons]\n",
    "gene = [str(r.id) for r in clean_seq]\n",
    "aneal_f = [primer_tm_neb1(str(r)) for r in forward_primer]\n",
    "aneal_r = [primer_tm_neb1(str(r)) for r in r_primer]\n",
    "\n",
    "# Add forward and reverse overhangs\n",
    "forward_overhang = \"CTGAGCGGCCTCGTCTGCACAGGGTTGGCAAAT\"\n",
    "reverse_overhang = \"CTTGCTCACCATGGACTGGAAGTAGAGGTTCTC\"\n",
    "forward_primer_with_overhang = [forward_overhang + f for f in forward_primer]\n",
    "reverse_primer_with_overhang = [reverse_overhang + r for r in r_primer]\n",
    "\n",
    "#Calculates Ta\n",
    "\n",
    "ta= [primer_ta_neb(str(f.forward_primer.seq),str(f.reverse_primer.seq))  for f in amplicons]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd01b56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   template  \\\n",
      "0       lcl|KV907515.1_cds_OOF90661.1_10513   \n",
      "1  lcl|NC_036441.1_cds_XP_001826005.1_10339   \n",
      "2        lcl|KV907505.1_cds_OOF92982.1_7994   \n",
      "3              NC_036440.1:c3236563-3235134   \n",
      "\n",
      "                                            f_primer  \\\n",
      "0  CTGAGCGGCCTCGTCTGCACAGGGTTGGCAAATGTGTCTACGGGCA...   \n",
      "1  CTGAGCGGCCTCGTCTGCACAGGGTTGGCAAATGATAGTTTAGTTG...   \n",
      "2  CTGAGCGGCCTCGTCTGCACAGGGTTGGCAAATCTGGAGATGCAGA...   \n",
      "3  CTGAGCGGCCTCGTCTGCACAGGGTTGGCAAATCCATCTGCCAGCT...   \n",
      "\n",
      "                                            r_primer  f_tm  r_tm  ta  len_fw  \\\n",
      "0  CTTGCTCACCATGGACTGGAAGTAGAGGTTCTCAAACAAGACTGTT...    59    62  62      51   \n",
      "1  CTTGCTCACCATGGACTGGAAGTAGAGGTTCTCCATAATCACAGGG...    59    58  61      58   \n",
      "2  CTTGCTCACCATGGACTGGAAGTAGAGGTTCTCAAAAGCCGTTCTC...    59    61  62      53   \n",
      "3  CTTGCTCACCATGGACTGGAAGTAGAGGTTCTCCGGCAAATGCATG...    61    62  65      51   \n",
      "\n",
      "   len_rv  \n",
      "0      56  \n",
      "1      53  \n",
      "2      51  \n",
      "3      54  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'template': gene,\n",
    "    'f_primer': forward_primer_with_overhang,\n",
    "    'r_primer': reverse_primer_with_overhang,\n",
    "    'f_tm': aneal_f,\n",
    "    'r_tm': aneal_r,\n",
    "    'ta': ta\n",
    "})\n",
    "\n",
    "# Calculate and add columns for primer lengths\n",
    "df['len_fw'] = df['f_primer'].apply(lambda x: len(x))\n",
    "df['len_rv'] = df['r_primer'].apply(lambda x: len(x))\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efcff982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OOF90661_1', 'XP_001826005.1', 'OOF92982_1', 'NC_036440.1:c3236563']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "truncated_gene = []\n",
    "\n",
    "for template in gene:\n",
    "    # Try to extract protein name using regular expression\n",
    "    match = re.search(r'cds_([^_]+)[._]([^_]+)[._]\\d+', template)\n",
    "    \n",
    "    if match:\n",
    "        truncated_gene.append(f\"{match.group(1)}_{match.group(2)}\")\n",
    "    else:\n",
    "        # If the regular expression doesn't match, take the first 15 characters\n",
    "        truncated_gene.append(template[:20])\n",
    "\n",
    "print(truncated_gene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "87939c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names_fw = [name+'_fw' for name in truncated_gene]\n",
    "gene_names_rv = [name+'_rv' for name in truncated_gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3939b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m forward_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m: gene_names_fw, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSequence\u001b[39m\u001b[38;5;124m'\u001b[39m:forward_primer_with_overhang, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcentration\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25nm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPurification\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTD\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      2\u001b[0m reverse_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m: gene_names_rv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSequence\u001b[39m\u001b[38;5;124m'\u001b[39m:reverse_primer_with_overhang, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcentration\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25nm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPurification\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTD\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      4\u001b[0m idt_primers_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([forward_df, reverse_df],ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "forward_df = pd.DataFrame({'Name': gene_names_fw, 'Sequence':forward_primer_with_overhang, 'Concentration':'25nm', 'Purification': 'STD'})\n",
    "reverse_df = pd.DataFrame({'Name': gene_names_rv, 'Sequence':reverse_primer_with_overhang, 'Concentration':'25nm', 'Purification': 'STD'})\n",
    "\n",
    "idt_primers_result = pd.concat([forward_df, reverse_df],ignore_index=True)\n",
    "idt_primers_result\n",
    "\n",
    "output_excel_file = os.path.join(dir_f, \"IDT_primer.xlsx\")\n",
    "idt_primers_result.to_excel(output_excel_file, index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aedd9f94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ææ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mææ\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ææ' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
